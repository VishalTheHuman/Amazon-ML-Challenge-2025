{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd94636-02e1-4129-97c6-65255d4c885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Callable, Dict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffe9f05-e35a-45aa-968c-60c37c59cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train_with_features_384.csv\")\n",
    "test_df = pd.read_csv(\"./test_with_features_384.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d13d37-e9a3-4f3b-aa5e-7ded64c2eb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'catalog_content', 'image_link', 'price', 'parsed_input',\n",
       "       'hidden_0', 'hidden_1', 'hidden_2', 'hidden_3', 'hidden_4',\n",
       "       ...\n",
       "       'hidden_758', 'hidden_759', 'hidden_760', 'hidden_761', 'hidden_762',\n",
       "       'hidden_763', 'hidden_764', 'hidden_765', 'hidden_766', 'hidden_767'],\n",
       "      dtype='object', length=773)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812e48b8-3edf-4abe-bc4d-cbd73e2b889a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>catalog_content</th>\n",
       "      <th>image_link</th>\n",
       "      <th>price</th>\n",
       "      <th>parsed_input</th>\n",
       "      <th>hidden_0</th>\n",
       "      <th>hidden_1</th>\n",
       "      <th>hidden_2</th>\n",
       "      <th>hidden_3</th>\n",
       "      <th>hidden_4</th>\n",
       "      <th>...</th>\n",
       "      <th>hidden_758</th>\n",
       "      <th>hidden_759</th>\n",
       "      <th>hidden_760</th>\n",
       "      <th>hidden_761</th>\n",
       "      <th>hidden_762</th>\n",
       "      <th>hidden_763</th>\n",
       "      <th>hidden_764</th>\n",
       "      <th>hidden_765</th>\n",
       "      <th>hidden_766</th>\n",
       "      <th>hidden_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33127</td>\n",
       "      <td>Item Name: La Victoria Green Taco Sauce Mild, ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51mo8htwTH...</td>\n",
       "      <td>4.89</td>\n",
       "      <td>La Victoria Green Taco Sauce Mild, 12 Ounce (P...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.044933</td>\n",
       "      <td>-0.029134</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>-0.009784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005760</td>\n",
       "      <td>0.039948</td>\n",
       "      <td>0.021019</td>\n",
       "      <td>-0.005191</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>0.051639</td>\n",
       "      <td>-0.010311</td>\n",
       "      <td>-0.032146</td>\n",
       "      <td>0.002894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>198967</td>\n",
       "      <td>Item Name: Salerno Cookies, The Original Butte...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71YtriIHAA...</td>\n",
       "      <td>13.12</td>\n",
       "      <td>Salerno Cookies, The Original Butter Cookies, ...</td>\n",
       "      <td>-0.010102</td>\n",
       "      <td>0.034376</td>\n",
       "      <td>-0.007231</td>\n",
       "      <td>0.019871</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063794</td>\n",
       "      <td>0.037696</td>\n",
       "      <td>-0.001306</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>-0.002965</td>\n",
       "      <td>0.092735</td>\n",
       "      <td>-0.003079</td>\n",
       "      <td>-0.040803</td>\n",
       "      <td>0.038916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261251</td>\n",
       "      <td>Item Name: Bear Creek Hearty Soup Bowl, Creamy...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51+PFEe-w-...</td>\n",
       "      <td>1.97</td>\n",
       "      <td>Bear Creek Hearty Soup Bowl, Creamy Chicken wi...</td>\n",
       "      <td>0.028091</td>\n",
       "      <td>0.038097</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.035106</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031041</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>0.016486</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>-0.050079</td>\n",
       "      <td>-0.042624</td>\n",
       "      <td>0.008628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55858</td>\n",
       "      <td>Item Name: Judee’s Blue Cheese Powder 11.25 oz...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41mu0HAToD...</td>\n",
       "      <td>30.34</td>\n",
       "      <td>Judee’s Blue Cheese Powder 11.25 oz - Gluten-F...</td>\n",
       "      <td>-0.009852</td>\n",
       "      <td>0.039714</td>\n",
       "      <td>-0.035323</td>\n",
       "      <td>0.043441</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036955</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>0.025755</td>\n",
       "      <td>0.019191</td>\n",
       "      <td>-0.005598</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>-0.031266</td>\n",
       "      <td>-0.051086</td>\n",
       "      <td>0.030734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292686</td>\n",
       "      <td>Item Name: kedem Sherry Cooking Wine, 12.7 Oun...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41sA037+Qv...</td>\n",
       "      <td>66.49</td>\n",
       "      <td>kedem Sherry Cooking Wine, 12.7 Ounce - 12 per...</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.014897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050469</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>0.018327</td>\n",
       "      <td>0.022207</td>\n",
       "      <td>-0.013384</td>\n",
       "      <td>0.071318</td>\n",
       "      <td>-0.043456</td>\n",
       "      <td>-0.030218</td>\n",
       "      <td>0.042696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 773 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                    catalog_content  \\\n",
       "0      33127  Item Name: La Victoria Green Taco Sauce Mild, ...   \n",
       "1     198967  Item Name: Salerno Cookies, The Original Butte...   \n",
       "2     261251  Item Name: Bear Creek Hearty Soup Bowl, Creamy...   \n",
       "3      55858  Item Name: Judee’s Blue Cheese Powder 11.25 oz...   \n",
       "4     292686  Item Name: kedem Sherry Cooking Wine, 12.7 Oun...   \n",
       "\n",
       "                                          image_link  price  \\\n",
       "0  https://m.media-amazon.com/images/I/51mo8htwTH...   4.89   \n",
       "1  https://m.media-amazon.com/images/I/71YtriIHAA...  13.12   \n",
       "2  https://m.media-amazon.com/images/I/51+PFEe-w-...   1.97   \n",
       "3  https://m.media-amazon.com/images/I/41mu0HAToD...  30.34   \n",
       "4  https://m.media-amazon.com/images/I/41sA037+Qv...  66.49   \n",
       "\n",
       "                                        parsed_input  hidden_0  hidden_1  \\\n",
       "0  La Victoria Green Taco Sauce Mild, 12 Ounce (P...  0.000263  0.044933   \n",
       "1  Salerno Cookies, The Original Butter Cookies, ... -0.010102  0.034376   \n",
       "2  Bear Creek Hearty Soup Bowl, Creamy Chicken wi...  0.028091  0.038097   \n",
       "3  Judee’s Blue Cheese Powder 11.25 oz - Gluten-F... -0.009852  0.039714   \n",
       "4  kedem Sherry Cooking Wine, 12.7 Ounce - 12 per...  0.010596  0.012416   \n",
       "\n",
       "   hidden_2  hidden_3  hidden_4  ...  hidden_758  hidden_759  hidden_760  \\\n",
       "0 -0.029134  0.021077 -0.009784  ...   -0.005760    0.039948    0.021019   \n",
       "1 -0.007231  0.019871  0.007795  ...   -0.063794    0.037696   -0.001306   \n",
       "2 -0.011193  0.035106  0.021745  ...   -0.031041    0.023984    0.000819   \n",
       "3 -0.035323  0.043441  0.007543  ...   -0.036955    0.007519    0.030852   \n",
       "4  0.008149  0.038313  0.014897  ...   -0.050469    0.034222    0.011103   \n",
       "\n",
       "   hidden_761  hidden_762  hidden_763  hidden_764  hidden_765  hidden_766  \\\n",
       "0   -0.005191    0.011502   -0.009000    0.051639   -0.010311   -0.032146   \n",
       "1    0.042444    0.022255   -0.002965    0.092735   -0.003079   -0.040803   \n",
       "2    0.018358    0.016486    0.002006    0.043939   -0.050079   -0.042624   \n",
       "3    0.025755    0.019191   -0.005598    0.020466   -0.031266   -0.051086   \n",
       "4    0.018327    0.022207   -0.013384    0.071318   -0.043456   -0.030218   \n",
       "\n",
       "   hidden_767  \n",
       "0    0.002894  \n",
       "1    0.038916  \n",
       "2    0.008628  \n",
       "3    0.030734  \n",
       "4    0.042696  \n",
       "\n",
       "[5 rows x 773 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0fbae3-1c2e-4fab-a32c-e904f8e099b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb675022-8370-4d24-b1be-3d2af03223fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # df → your dataframe\n",
    "train_df_train, train_df_val = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.1,       # 20% test split\n",
    "    random_state=42,     # reproducibility\n",
    "    shuffle=True         # always shuffle before splitting\n",
    ")\n",
    "\n",
    "price_threshold = train_df_train[\"price\"].quantile(0.99)\n",
    "train_df_train = train_df_train[train_df_train[\"price\"] <= price_threshold].reset_index(drop=True)\n",
    "train_df_val = train_df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425efcc4-0909-4d9b-a51a-12316d4d720a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'catalog_content', 'image_link', 'price', 'parsed_input',\n",
       "       'hidden_0', 'hidden_1', 'hidden_2', 'hidden_3', 'hidden_4',\n",
       "       ...\n",
       "       'hidden_758', 'hidden_759', 'hidden_760', 'hidden_761', 'hidden_762',\n",
       "       'hidden_763', 'hidden_764', 'hidden_765', 'hidden_766', 'hidden_767'],\n",
       "      dtype='object', length=773)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6a0df9-47ed-4f30-add4-cca9d5369932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential, readable, and easily-extendable text-only feature engineering pipeline.\n",
    "# This will run on the CSV you provided earlier and print a preview of new, meaningful features.\n",
    "# Each step is its own function and returns the dataframe (so steps can be applied in order).\n",
    "# To add a new feature step, create a function with signature `def step_xxx(df: pd.DataFrame) -> pd.DataFrame:`\n",
    "# and append it to `pipeline_steps` in `run_text_feature_pipeline`.\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def _clean_text(s: str) -> str:\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def _lower(s: str) -> str:\n",
    "    return _clean_text(s).lower()\n",
    "\n",
    "# ---------- Step 1: Parse catalog_content ----------\n",
    "def step_1_parse_catalog(df: pd.DataFrame, catalog_col: str = 'catalog_content') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse raw catalog_content into structured fields:\n",
    "      - item_name (string)\n",
    "      - bullets (list of strings)\n",
    "      - value_total (numeric if present)\n",
    "      - unit_field (string if present)\n",
    "    \"\"\"\n",
    "    def extract_item_name(s: str) -> str:\n",
    "        m = re.search(r'Item Name:\\s*(.*?)(?:\\n|$)', str(s), flags=re.I|re.S)\n",
    "        return _clean_text(m.group(1)) if m else \"\"\n",
    "    def extract_bullets(s: str) -> List[str]:\n",
    "        bullets = re.findall(r'Bullet Point\\s*\\d+:\\s*(.*?)(?:\\n|$)', str(s), flags=re.I|re.S)\n",
    "        return [ _clean_text(b) for b in bullets ]\n",
    "    def extract_value(s: str) -> float:\n",
    "        m = re.search(r'Value:\\s*([0-9]+(?:\\.[0-9]+)?)', str(s), flags=re.I)\n",
    "        return float(m.group(1)) if m else np.nan\n",
    "    def extract_unit_field(s: str) -> str:\n",
    "        m = re.search(r'Unit:\\s*([A-Za-z\\. ]+)', str(s), flags=re.I)\n",
    "        return _clean_text(m.group(1)) if m else \"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    df['item_name_raw'] = df[catalog_col].apply(extract_item_name)\n",
    "    df['bullets_list'] = df[catalog_col].apply(extract_bullets)\n",
    "    df['value_total'] = df[catalog_col].apply(extract_value)\n",
    "    df['unit_field_raw'] = df[catalog_col].apply(extract_unit_field)\n",
    "    return df\n",
    "\n",
    "# ---------- Step 2: Brand candidate heuristics ----------\n",
    "PRODUCT_STOP_WORDS = {\n",
    "    'pack','of','oz','ounce','ounces','fl','fl.','fl oz','pack of','box','bottle',\n",
    "    'cup','cups','tray','single','serve','packets','packet','bag','box','lb','pound'\n",
    "}\n",
    "\n",
    "def step_2_brand_candidate(df: pd.DataFrame, title_col: str = 'item_name_raw') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create brand candidate features:\n",
    "      - brand_candidate_15 : first 15 characters (lowercased)\n",
    "      - brand_candidate_2words : first up-to-two alphabetic words (max 2 words), lowercased\n",
    "      - brand_candidate (preferred) : prefer 2-words if they don't look like product words\n",
    "    \"\"\"\n",
    "    def candidate_15(s: str) -> str:\n",
    "        return _lower(s[:15])\n",
    "    def candidate_2words(s: str) -> str:\n",
    "        s = _lower(s)\n",
    "        words = re.findall(r\"[a-zA-Z']+\", s)\n",
    "        picked = []\n",
    "        for w in words[:2]:\n",
    "            if w in PRODUCT_STOP_WORDS:\n",
    "                break\n",
    "            picked.append(w)\n",
    "        return \" \".join(picked) if picked else _lower(words[0]) if words else \"\"\n",
    "    def choose_preferred(s: str):\n",
    "        two = candidate_2words(s)\n",
    "        if two and len(two) > 0:\n",
    "            return two\n",
    "        return candidate_15(s)\n",
    "\n",
    "    df = df.copy()\n",
    "    df['brand_candidate_15'] = df[title_col].fillna(\"\").apply(candidate_15)\n",
    "    df['brand_candidate_2words'] = df[title_col].fillna(\"\").apply(candidate_2words)\n",
    "    df['brand_candidate'] = df[title_col].fillna(\"\").apply(choose_preferred)\n",
    "    return df\n",
    "\n",
    "# ---------- Step 3: Size and pack extraction (text-only) ----------\n",
    "UNIT_MAP = {\n",
    "    'oz': 'oz', 'ounce': 'oz', 'ounces': 'oz', 'fl oz': 'fl_oz', 'fl. oz': 'fl_oz',\n",
    "    'g': 'g', 'gram': 'g', 'grams': 'g', 'kg': 'kg', 'ml': 'ml', 'l': 'l', 'lb': 'lb', 'pound': 'lb'\n",
    "}\n",
    "\n",
    "def step_3_extract_size_pack(df: pd.DataFrame, title_col: str = 'item_name_raw') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract size (numeric) and unit (normalized), and pack count from title text (or infer from value_total).\n",
    "    Only uses text fields already present (no price usage).\n",
    "    \"\"\"\n",
    "    def find_size_unit(s: str):\n",
    "        # common patterns: \"12 Ounce\", \"1.9 Ounce\", \"12 fl oz\", \"12fl oz\", \"12oz\"\n",
    "        s0 = s.lower()\n",
    "        m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(fl oz|fl\\. oz|ounce|ounces|oz|g|grams|gram|kg|ml|l|pound|lb)\\b', s0)\n",
    "        if m:\n",
    "            val = float(m.group(1))\n",
    "            raw_unit = m.group(2)\n",
    "            normalized = UNIT_MAP.get(raw_unit.replace('.', '').strip(), raw_unit)\n",
    "            return val, normalized\n",
    "        # fallback: contiguous digits followed by oz or g with no space\n",
    "        m2 = re.search(r'(\\d+(?:\\.\\d+)?)(oz|g|kg|ml|l)\\b', s.lower())\n",
    "        if m2:\n",
    "            val = float(m2.group(1))\n",
    "            normalized = UNIT_MAP.get(m2.group(2), m2.group(2))\n",
    "            return val, normalized\n",
    "        return np.nan, \"\"\n",
    "\n",
    "    def find_pack_count(s: str):\n",
    "        s0 = s.lower()\n",
    "        # explicit \"pack of N\", \"(Pack of N)\", \"Pack N\", \"N pack\"\n",
    "        m = re.search(r'pack(?:\\s*of)?\\s*(\\d+)', s0)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "        m2 = re.search(r'\\b(\\d+)\\s*-\\s*pack\\b', s0)\n",
    "        if m2:\n",
    "            return int(m2.group(1))\n",
    "        # \"4-pack\" or \"6 pack\" or \"6-pack\"\n",
    "        m3 = re.search(r'(\\d+)[\\s-]*pack\\b', s0)\n",
    "        if m3:\n",
    "            return int(m3.group(1))\n",
    "        return np.nan\n",
    "\n",
    "    df = df.copy()\n",
    "    sizes = df[title_col].fillna(\"\").apply(find_size_unit)\n",
    "    df['item_unit_size_from_title'] = sizes.apply(lambda t: t[0])\n",
    "    df['item_unit_type_from_title'] = sizes.apply(lambda t: t[1])\n",
    "\n",
    "    df['pack_count_from_title'] = df[title_col].apply(find_pack_count)\n",
    "    # infer pack_count using value_total if title missing and value_total available\n",
    "    def infer_pack(r):\n",
    "        if not pd.isna(r.get('pack_count_from_title')):\n",
    "            return r['pack_count_from_title']\n",
    "        if not pd.isna(r.get('value_total')) and not pd.isna(r.get('item_unit_size_from_title')) and r['item_unit_size_from_title']>0:\n",
    "            approx = r['value_total'] / r['item_unit_size_from_title']\n",
    "            if approx>0:\n",
    "                # round to nearest integer if close\n",
    "                if abs(round(approx)-approx) / max(approx,1e-6) < 0.05:\n",
    "                    return int(round(approx))\n",
    "        return np.nan\n",
    "\n",
    "    df['pack_count_inferred'] = df.apply(infer_pack, axis=1)\n",
    "    # final pack count prefer explicit title then inferred then NaN\n",
    "    df['pack_count_text'] = df['pack_count_from_title'].fillna(df['pack_count_inferred'])\n",
    "\n",
    "    # normalized unit field preference: title -> unit_field_raw -> unknown\n",
    "    df['unit_normalized'] = df['item_unit_type_from_title']\n",
    "    df.loc[df['unit_normalized']== \"\", 'unit_normalized'] = df['unit_field_raw'].str.lower().fillna(\"\")\n",
    "    return df\n",
    "\n",
    "def step_3b_normalize_units(df):\n",
    "    \"\"\"\n",
    "    Normalize all numeric size/value quantities to a common comparable unit.\n",
    "    - Liquids → milliliters (ml)\n",
    "    - Solids  → grams (g)\n",
    "    - Counts  → units (pcs)\n",
    "    \"\"\"\n",
    "    # Common unit conversion tables\n",
    "    to_ml = {\n",
    "        \"fl oz\": 29.5735,\n",
    "        \"ounce\": 29.5735,\n",
    "        \"oz\": 29.5735,\n",
    "        \"pint\": 473.176,\n",
    "        \"quart\": 946.353,\n",
    "        \"gallon\": 3785.41,\n",
    "        \"ml\": 1.0,\n",
    "        \"l\": 1000.0,\n",
    "        \"liter\": 1000.0\n",
    "    }\n",
    "    to_g = {\n",
    "        \"oz\": 28.3495,\n",
    "        \"ounce\": 28.3495,\n",
    "        \"lb\": 453.592,\n",
    "        \"pound\": 453.592,\n",
    "        \"g\": 1.0,\n",
    "        \"gram\": 1.0,\n",
    "        \"kg\": 1000.0,\n",
    "        \"kilogram\": 1000.0\n",
    "    }\n",
    "    to_units = {\n",
    "        \"count\": 1.0,\n",
    "        \"piece\": 1.0,\n",
    "        \"pack\": 1.0,\n",
    "        \"pcs\": 1.0,\n",
    "        \"unit\": 1.0\n",
    "    }\n",
    "\n",
    "    def normalize_row(row):\n",
    "        unit = str(row.get(\"unit_normalized\", \"\")).lower().strip()\n",
    "        value = row.get(\"item_unit_size_from_title\") or row.get(\"value_total\")\n",
    "        if value is None or pd.isna(value):\n",
    "            return np.nan, None\n",
    "        \n",
    "        # Match the right conversion table\n",
    "        if unit in to_ml:\n",
    "            return value * to_ml[unit], \"ml\"\n",
    "        elif unit in to_g:\n",
    "            return value * to_g[unit], \"g\"\n",
    "        elif unit in to_units:\n",
    "            return value * to_units[unit], \"unit\"\n",
    "        else:\n",
    "            return value, None  # unknown unit, keep as is\n",
    "\n",
    "    df[[\"normalized_value\", \"normalized_unit\"]] = df.apply(\n",
    "        lambda r: pd.Series(normalize_row(r)), axis=1\n",
    "    )\n",
    "\n",
    "    # # Create price per normalized unit (e.g. per gram or per ml)\n",
    "    # df[\"price_per_norm_unit\"] = df.apply(\n",
    "    #     lambda r: r[\"price\"] / r[\"normalized_value\"]\n",
    "    #     if pd.notna(r[\"normalized_value\"]) and r[\"normalized_value\"] > 0\n",
    "    #     else np.nan,\n",
    "    #     axis=1\n",
    "    # )\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------- Step 4: Lexical & readability features ----------\n",
    "def step_4_lexical_features(df: pd.DataFrame, title_col: str = 'item_name_raw') -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    def stats(s: str) -> Dict:\n",
    "        s_clean = _clean_text(s)\n",
    "        s_low = s_clean.lower()\n",
    "        words = re.findall(r\"\\w+\", s_clean)\n",
    "        word_count = len(words)\n",
    "        unique_word_count = len(set([w.lower() for w in words]))\n",
    "        avg_word_len = np.mean([len(w) for w in words]) if words else 0\n",
    "        digit_count = sum(ch.isdigit() for ch in s_clean)\n",
    "        punct_count = sum(1 for ch in s_clean if ch in '.,:;()[]/+-&%$')\n",
    "        uppercase_words = sum(1 for w in s_clean.split() if any(ch.isupper() for ch in w))\n",
    "        return {\n",
    "            'title_word_count': word_count,\n",
    "            'title_unique_word_count': unique_word_count,\n",
    "            'title_avg_word_len': avg_word_len,\n",
    "            'title_digit_count': digit_count,\n",
    "            'title_punct_count': punct_count,\n",
    "            'title_uppercase_word_count': uppercase_words,\n",
    "            'title_char_count': len(s_clean)\n",
    "        }\n",
    "    lex = df[title_col].fillna(\"\").apply(stats).apply(pd.Series)\n",
    "    return pd.concat([df.reset_index(drop=True), lex.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ---------- Step 5: Bullets features ----------\n",
    "def step_5_bullets_features(df: pd.DataFrame, bullets_col: str = 'bullets_list') -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    def bullet_stats(bullets: List[str]):\n",
    "        if not bullets:\n",
    "            return {\n",
    "                'bullet_count': 0,\n",
    "                'bullets_combined': \"\",\n",
    "                'bullets_word_count': 0,\n",
    "                'bullets_num_digits': 0,\n",
    "                'bullets_avg_len': 0\n",
    "            }\n",
    "        combined = \" \".join(bullets)\n",
    "        words = re.findall(r\"\\w+\", combined)\n",
    "        nums = sum(ch.isdigit() for ch in combined)\n",
    "        lens = [len(b) for b in bullets]\n",
    "        return {\n",
    "            'bullet_count': len(bullets),\n",
    "            'bullets_combined': combined,\n",
    "            'bullets_word_count': len(words),\n",
    "            'bullets_num_digits': nums,\n",
    "            'bullets_avg_len': np.mean(lens) if lens else 0\n",
    "        }\n",
    "    bfeat = df[bullets_col].apply(bullet_stats).apply(pd.Series)\n",
    "    return pd.concat([df.reset_index(drop=True), bfeat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# ---------- Step 6: Keyword flags (meaningful features) ----------\n",
    "KEYWORDS = [\n",
    "    'premium','premium quality','organic','butter','real butter','trusted brand','single serve',\n",
    "    'family pack','variety pack','classic','original','mild','spicy','creamy','hearty','easy to prepare',\n",
    "    'zero grams','0 grams','trans fat','low sodium','gluten free','no sugar','sugar free','imported',\n",
    "    'gourmet','artisan','artisanal','bulk','best seller','new','fresh'\n",
    "]\n",
    "\n",
    "def step_6_keyword_flags(df: pd.DataFrame, text_cols: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create binary flags for presence of meaningful keywords across provided text columns\n",
    "    (defaults to item_name_raw + bullets_combined + catalog_content)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if text_cols is None:\n",
    "        text_cols = ['item_name_raw', 'bullets_combined', 'catalog_content']\n",
    "\n",
    "    # build a lowercase combined field for keyword search\n",
    "    df['__text_search_field'] = df[text_cols].fillna(\"\").agg(\" \".join, axis=1).str.lower()\n",
    "\n",
    "    for kw in KEYWORDS:\n",
    "        colname = 'kw_' + re.sub(r'[^a-z0-9]+', '_', kw.strip().lower())\n",
    "        df[colname] = df['__text_search_field'].str.contains(re.escape(kw), regex=True).astype(int)\n",
    "    # also add a keyword richness score\n",
    "    kw_cols = [c for c in df.columns if c.startswith('kw_')]\n",
    "    df['kw_count'] = df[kw_cols].sum(axis=1)\n",
    "    df.drop(columns=['__text_search_field'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# ---------- Step 7: Optional TF-IDF (compact top-n components) ----------\n",
    "def step_7_tfidf_topn(df: pd.DataFrame, text_col: str = 'item_name_raw', top_n: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fit a small TF-IDF on titles and add top_n TF-IDF feature columns (tfidf_0 ... tfidf_{n-1}).\n",
    "    This keeps the pipeline text-only but gives dense numeric summarization of the title.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    corpus = df[text_col].fillna(\"\").astype(str).tolist()\n",
    "    vect = TfidfVectorizer(ngram_range=(1,2), max_features=1000, stop_words='english')\n",
    "    X = vect.fit_transform(corpus)\n",
    "    # reduce to top_n dimensions by taking highest-variance columns (simple heuristic)\n",
    "    # compute column variances\n",
    "    import numpy as _np\n",
    "    col_vars = _np.array(X.toarray()).var(axis=0)\n",
    "    if X.shape[1] == 0:\n",
    "        # no features produced\n",
    "        for i in range(top_n):\n",
    "            df[f'tfidf_{i}'] = 0.0\n",
    "        return df\n",
    "    idxs = col_vars.argsort()[::-1][:min(top_n, X.shape[1])]\n",
    "    Xarr = X.toarray()[:, idxs]\n",
    "    # insert into df as tfidf_0 ... tfidf_{k-1}\n",
    "    for i in range(Xarr.shape[1]):\n",
    "        df[f'tfidf_{i}'] = Xarr[:, i]\n",
    "    # if less than top_n created, pad remaining with zeros\n",
    "    for i in range(Xarr.shape[1], top_n):\n",
    "        df[f'tfidf_{i}'] = 0.0\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# # ---------- Run pipeline on sample data and show a compact preview ----------\n",
    "# df_features = run_text_feature_pipeline(df_raw)\n",
    "\n",
    "# # Display a subset of informative columns for preview\n",
    "# cols_to_show = [\n",
    "#     'sample_id','item_name_raw','brand_candidate','brand_candidate_15','brand_candidate_2words',\n",
    "#     'item_unit_size_from_title','item_unit_type_from_title','pack_count_from_title','pack_count_inferred','pack_count_text','unit_normalized',\n",
    "#     'title_word_count','title_char_count','title_unique_word_count','title_avg_word_len' if 'title_avg_word_len' in df_features.columns else 'title_avg_word_len',\n",
    "#     'bullet_count','bullets_word_count','bullets_avg_len',\n",
    "#     'kw_count'\n",
    "# ]\n",
    "# # filter only existing columns\n",
    "# cols_to_show = [c for c in cols_to_show if c in df_features.columns]\n",
    "\n",
    "# df_preview = df_features[cols_to_show].copy()\n",
    "# df_preview.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Show the preview (this will be visible in the notebook output)\n",
    "# df_preview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62fea1c0-3c5c-489b-85b5-d6a9a6fb55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_train_text_feature_pipeline(df):\n",
    "#     df = step_1_parse_catalog(df)\n",
    "#     df = step_2_brand_candidate(df)\n",
    "#     df = step_3_extract_size_pack(df)\n",
    "#     df = step_3b_normalize_units(df)   # ⬅️ add this line here\n",
    "#     df = step_4_lexical_features(df)\n",
    "#     df = step_5_bullets_features(df)\n",
    "#     df = step_6_keyword_flags(df)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21fba4f4-b874-436b-a8b4-f766e0c52abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dname, dset in [(\"train\", train_df_train), (\"val\", train_df_val), (\"test\", test_df)]:\n",
    "    dset = step_1_parse_catalog(dset)\n",
    "    dset = step_2_brand_candidate(dset)\n",
    "    dset = step_3_extract_size_pack(dset)\n",
    "    dset = step_3b_normalize_units(dset)\n",
    "    dset = step_4_lexical_features(dset)\n",
    "    dset = step_5_bullets_features(dset)\n",
    "    dset = step_7_tfidf_topn(dset)\n",
    "    \n",
    "    if dname == \"train\":\n",
    "        train_df_train = dset\n",
    "    elif dname == \"val\":\n",
    "        train_df_val = dset\n",
    "    else:\n",
    "        test_df = dset\n",
    "\n",
    "# # # Compute brand-level maps from train\n",
    "# brand_stats = train_df_train.groupby(\"brand_candidate\")[\"price\"].agg([\"median\"])\n",
    "# brand_stats_dict = brand_stats.to_dict()  # nested dicts: {\"mean\": {...}, \"median\": {...}, ...}\n",
    "\n",
    "# def populate_from_hashmaps(df, brand_stats_dict):\n",
    "#     for stat_name, mapping in brand_stats_dict.items():\n",
    "#         df[f\"brand_price_{stat_name}\"] = df[\"brand_candidate\"].map(mapping)\n",
    "#     return df\n",
    "\n",
    "# train_df_train = populate_from_hashmaps(train_df_train, brand_stats_dict)\n",
    "# train_df_val = populate_from_hashmaps(train_df_val, brand_stats_dict)\n",
    "\n",
    "\n",
    "# for stat in [\"mean\", \"median\", \"max\", \"min\"]:\n",
    "    # train_df_train[f\"price_vs_brand_{stat}\"] = train_df_train[\"price\"] / train_df_train[f\"brand_price_{stat}\"]\n",
    "    # train_df_val[f\"price_vs_brand_{stat}\"] = train_df_val[\"price\"] / train_df_val[f\"brand_price_{stat}\"]\n",
    "\n",
    "    # train_df_train[f\"price_vs_brand_{stat}\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    # train_df_val[f\"price_vs_brand_{stat}\"].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # train_df_train[f\"price_vs_brand_{stat}\"].fillna(1.0, inplace=True)\n",
    "    # train_df_val[f\"price_vs_brand_{stat}\"].fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "875b8e09-4aa6-4e84-b7c5-88ecab9c8989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'catalog_content', 'image_link', 'price', 'parsed_input',\n",
       "       'hidden_0', 'hidden_1', 'hidden_2', 'hidden_3', 'hidden_4',\n",
       "       ...\n",
       "       'title_digit_count', 'title_punct_count', 'title_uppercase_word_count',\n",
       "       'title_char_count', 'bullet_count', 'bullets_combined',\n",
       "       'bullets_word_count', 'bullets_num_digits', 'bullets_avg_len',\n",
       "       'tfidf_0'],\n",
       "      dtype='object', length=801)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72933617-d572-4b6f-ae50-3e256ab62ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'catalog_content', 'image_link', 'price', 'parsed_input',\n",
       "       'hidden_0', 'hidden_1', 'hidden_2', 'hidden_3', 'hidden_4',\n",
       "       ...\n",
       "       'title_digit_count', 'title_punct_count', 'title_uppercase_word_count',\n",
       "       'title_char_count', 'bullet_count', 'bullets_combined',\n",
       "       'bullets_word_count', 'bullets_num_digits', 'bullets_avg_len',\n",
       "       'tfidf_0'],\n",
       "      dtype='object', length=801)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cc9a49b-dccd-43d8-ac10-f532ca36e619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b64522d3-58ab-44ab-a958-26c09df535b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 786\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttrain's huber: 0.231901\tval's huber: 0.271444\n",
      "[200]\ttrain's huber: 0.197708\tval's huber: 0.252685\n",
      "[300]\ttrain's huber: 0.175149\tval's huber: 0.243822\n",
      "[400]\ttrain's huber: 0.1575\tval's huber: 0.238263\n",
      "[500]\ttrain's huber: 0.142465\tval's huber: 0.234066\n",
      "[600]\ttrain's huber: 0.129776\tval's huber: 0.230629\n",
      "[700]\ttrain's huber: 0.118648\tval's huber: 0.228471\n",
      "[800]\ttrain's huber: 0.108608\tval's huber: 0.226481\n",
      "[900]\ttrain's huber: 0.0995591\tval's huber: 0.224688\n",
      "[1000]\ttrain's huber: 0.0913451\tval's huber: 0.22319\n",
      "[1100]\ttrain's huber: 0.0839781\tval's huber: 0.221943\n",
      "[1200]\ttrain's huber: 0.0773583\tval's huber: 0.220941\n",
      "[1300]\ttrain's huber: 0.0712063\tval's huber: 0.219885\n",
      "[1400]\ttrain's huber: 0.0658057\tval's huber: 0.218892\n",
      "[1500]\ttrain's huber: 0.0608582\tval's huber: 0.218233\n",
      "[1600]\ttrain's huber: 0.0562119\tval's huber: 0.217305\n",
      "[1700]\ttrain's huber: 0.0520791\tval's huber: 0.216742\n",
      "[1800]\ttrain's huber: 0.0482642\tval's huber: 0.216158\n",
      "[1900]\ttrain's huber: 0.0448146\tval's huber: 0.215439\n",
      "[2000]\ttrain's huber: 0.041555\tval's huber: 0.214981\n",
      "[2100]\ttrain's huber: 0.038623\tval's huber: 0.214632\n",
      "[2200]\ttrain's huber: 0.0359205\tval's huber: 0.214311\n",
      "[2300]\ttrain's huber: 0.0333586\tval's huber: 0.213965\n",
      "[2400]\ttrain's huber: 0.0310394\tval's huber: 0.213552\n",
      "[2500]\ttrain's huber: 0.028879\tval's huber: 0.213156\n",
      "[2600]\ttrain's huber: 0.0269573\tval's huber: 0.21298\n",
      "[2700]\ttrain's huber: 0.025115\tval's huber: 0.212611\n",
      "[2800]\ttrain's huber: 0.0234608\tval's huber: 0.212337\n",
      "[2900]\ttrain's huber: 0.0219343\tval's huber: 0.212047\n",
      "[3000]\ttrain's huber: 0.0204528\tval's huber: 0.211843\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2999]\ttrain's huber: 0.0204667\tval's huber: 0.21184\n",
      "\n",
      "Validation SMAPE: 52.40%\n",
      "\n",
      "Features actually used: 786 out of 786 (100.0%)\n",
      "\n",
      "Top 25 Features:\n",
      "                   feature   importance  split_count\n",
      "       pack_count_inferred 36909.419691          932\n",
      "          normalized_value 30906.227988         1273\n",
      "         title_digit_count 29385.606845          487\n",
      "          title_char_count 18945.239201          856\n",
      "           pack_count_text 17421.006625          356\n",
      "     pack_count_from_title 17136.449010         1246\n",
      "               value_total 16731.875944         1338\n",
      " item_unit_size_from_title  6435.847562          926\n",
      "           bullets_avg_len  5767.271670          558\n",
      "                hidden_262  5462.263482          311\n",
      "         title_punct_count  5457.755091          323\n",
      "                hidden_384  5148.718618          312\n",
      "                 hidden_36  5095.647109          267\n",
      "                hidden_750  5075.777382          465\n",
      "                hidden_151  5065.132464          315\n",
      "                   tfidf_0  4144.122692          131\n",
      "                hidden_250  3674.856389          303\n",
      "                hidden_341  3112.266137          329\n",
      "        bullets_num_digits  2953.769406          361\n",
      "        title_avg_word_len  2897.513102         1104\n",
      "                hidden_467  2752.209039          297\n",
      "                hidden_615  2583.316082          314\n",
      "title_uppercase_word_count  2544.309909          415\n",
      "        bullets_word_count  2485.657441          523\n",
      "                hidden_248  2478.985173          249\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (75000) does not match length of index (7500)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m test_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(test_output)\n\u001b[1;32m    105\u001b[0m output_df \u001b[38;5;241m=\u001b[39m train_df_val[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m--> 106\u001b[0m \u001b[43moutput_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m test_output\n\u001b[1;32m    107\u001b[0m output_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4530\u001b[0m     ):\n\u001b[1;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m/root/miniconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (75000) does not match length of index (7500)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculate Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    return 100 * np.mean(\n",
    "        2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + 1e-8)\n",
    "    )\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [\n",
    "    c for c in train_df_train.columns\n",
    "    if c not in [\"sample_id\", \"price\", \"item_name_raw\", \"catalog_content\", \"image_link\"]\n",
    "    and train_df_train[c].dtype != \"O\"\n",
    "]\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "\n",
    "# Prepare train data\n",
    "X_train = train_df_train[feature_cols]\n",
    "y_train = train_df_train[\"price\"]\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = train_df_val[feature_cols]\n",
    "y_val = train_df_val[\"price\"]\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "\n",
    "# Transform target to log scale\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "# Create LightGBM datasets\n",
    "train_ds = lgb.Dataset(X_train, label=y_train_log)\n",
    "val_ds = lgb.Dataset(X_val, label=y_val_log, reference=train_ds)\n",
    "\n",
    "# Parameters optimized to use MORE features\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"huber\",\n",
    "    \"learning_rate\": 0.03,  # Lower learning rate for more complex model\n",
    "    \"num_leaves\": 64,  # Increased from 31 to handle more features\n",
    "    \"max_depth\": 8,  # Control depth to avoid overfitting\n",
    "    \"min_child_samples\": 10,  # Allow smaller leaf nodes\n",
    "    \n",
    "    # Feature usage parameters - KEY for using more features\n",
    "    \"feature_fraction\": 0.8,  # Use ALL features (was 0.9)\n",
    "    \"feature_fraction_bynode\": 0.8,  # Use 80% features per split\n",
    "    \n",
    "    # Bagging parameters\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \n",
    "    # Regularization to prevent overfitting with many features\n",
    "    \"reg_alpha\": 0.1,  # L1 regularization\n",
    "    \"reg_lambda\": 0.25,  # L2 regularization\n",
    "    \"min_gain_to_split\": 0.01,  # Minimum gain to make split\n",
    "    \n",
    "    # Other params\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "    \"force_col_wise\": True,  # Better for many features\n",
    "}\n",
    "\n",
    "# Train model with more rounds for complex model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_ds,\n",
    "    valid_sets=[train_ds, val_ds],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    num_boost_round=3000,  # Increased from 2000\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(150),  # More patience\n",
    "        lgb.log_evaluation(100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_log = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# Calculate SMAPE\n",
    "score = smape(y_val.values, y_pred)\n",
    "print(f\"\\nValidation SMAPE: {score:.2f}%\")\n",
    "\n",
    "# Analyze feature usage\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain'),\n",
    "    'split_count': model.feature_importance(importance_type='split')\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Count how many features are actually used\n",
    "features_used = (feature_importance['split_count'] > 0).sum()\n",
    "print(f\"\\nFeatures actually used: {features_used} out of {len(feature_cols)} ({100*features_used/len(feature_cols):.1f}%)\")\n",
    "\n",
    "print(\"\\nTop 25 Features:\")\n",
    "print(feature_importance.head(25).to_string(index=False))\n",
    "\n",
    "test_output = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "test_output = np.expm1(test_output)\n",
    "\n",
    "output_df = train_df_val[['sample_id']]\n",
    "output_df['price'] = test_output\n",
    "output_df.to_csv(\"out.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14da3348-409a-469c-b9bd-28c90dc1d54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 25 features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 25 Features:\")\n",
    "print(feature_importance.head(25).to_string(index=False))\n",
    "\n",
    "# Get list of top 25 feature names\n",
    "top_25_features = feature_importance.head(25)['feature'].tolist()\n",
    "print(f\"\\nTop 25 feature names: {top_25_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13a5d988-8b8b-4ce0-92a1-ea84ce948911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dd521-6114-4bca-8f5c-cbf65bd4180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-11 15:47:36,351] A new study created in memory with name: lgb_price_prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 785\n",
      "\n",
      "================================================================================\n",
      "Starting Optuna Hyperparameter Tuning\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba95c263e9d41eabf2e061c9873cf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculate Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    return 100 * np.mean(\n",
    "        2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + 1e-8)\n",
    "    )\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [\n",
    "    c for c in train_df_train.columns\n",
    "    if c not in [\"sample_id\", \"price\", \"item_name_raw\", \"catalog_content\", \"image_link\"]\n",
    "    and train_df_train[c].dtype != \"O\"\n",
    "]\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "\n",
    "# Prepare train data\n",
    "X_train = train_df_train[feature_cols]\n",
    "y_train = train_df_train[\"price\"]\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = train_df_val[feature_cols]\n",
    "y_val = train_df_val[\"price\"]\n",
    "\n",
    "# Transform target to log scale\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "# Create LightGBM datasets\n",
    "train_ds = lgb.Dataset(X_train, label=y_train_log)\n",
    "val_ds = lgb.Dataset(X_val, label=y_val_log, reference=train_ds)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter tuning.\"\"\"\n",
    "    \n",
    "    # Suggest objective function\n",
    "    objective_type = trial.suggest_categorical(\"objective\", [\n",
    "        \"regression\",      # L2 loss (MSE)\n",
    "        \"regression_l1\",   # L1 loss (MAE) - robust to outliers\n",
    "        \"huber\",          # Huber loss - combines L1 and L2\n",
    "        \"fair\",           # Fair loss - another robust alternative\n",
    "        \"poisson\",        # Poisson regression - for count-like positive data\n",
    "        \"quantile\",       # Quantile regression\n",
    "        \"mape\",           # Mean Absolute Percentage Error\n",
    "    ])\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"objective\": objective_type,\n",
    "        \"metric\": \"mae\",\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": 42,\n",
    "        \"force_col_wise\": True,\n",
    "        \"feature_pre_filter\": False,  # Required for dynamic min_child_samples\n",
    "        \n",
    "        # Learning parameters\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 127),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 10.0, log=True),\n",
    "        \n",
    "        # Feature parameters\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.7, 1.0),\n",
    "        \"feature_fraction_bynode\": trial.suggest_float(\"feature_fraction_bynode\", 0.7, 1.0),\n",
    "        \n",
    "        # Bagging parameters\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 10),\n",
    "        \n",
    "        # Regularization\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0.0, 0.1),\n",
    "        \n",
    "        # Additional parameters\n",
    "        \"path_smooth\": trial.suggest_float(\"path_smooth\", 0.0, 1.0),\n",
    "    }\n",
    "    \n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_ds,\n",
    "        valid_sets=[val_ds],\n",
    "        valid_names=[\"val\"],\n",
    "        num_boost_round=2000,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(100),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Predict and calculate SMAPE\n",
    "    y_pred_log = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    score = smape(y_val.values, y_pred)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Starting Optuna Hyperparameter Tuning\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=TPESampler(seed=42),\n",
    "    study_name=\"lgb_price_prediction\"\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=100,  # Adjust number of trials as needed\n",
    "    timeout=None,\n",
    "    show_progress_bar=True,\n",
    "    n_jobs=1  # Set to -1 for parallel execution if you have multiple cores\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Optimization Complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest SMAPE Score: {study.best_value:.2f}%\")\n",
    "print(f\"Best iteration: {study.best_trial.number}\")\n",
    "print(\"\\nBest Parameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training Final Model with Best Parameters\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"mae\",\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "    \"force_col_wise\": True,\n",
    "    \"feature_pre_filter\": False,  # Required for dynamic min_child_samples\n",
    "})\n",
    "\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    train_ds,\n",
    "    valid_sets=[train_ds, val_ds],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    num_boost_round=3000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(150),\n",
    "        lgb.log_evaluation(100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Final predictions\n",
    "y_pred_log = final_model.predict(X_val, num_iteration=final_model.best_iteration)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "# Calculate final SMAPE\n",
    "final_score = smape(y_val.values, y_pred)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Final Validation SMAPE: {final_score:.2f}%\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Analyze feature usage\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': final_model.feature_importance(importance_type='gain'),\n",
    "    'split_count': final_model.feature_importance(importance_type='split')\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "features_used = (feature_importance['split_count'] > 0).sum()\n",
    "print(f\"Features actually used: {features_used} out of {len(feature_cols)} ({100*features_used/len(feature_cols):.1f}%)\")\n",
    "\n",
    "print(\"\\nTop 25 Features:\")\n",
    "print(feature_importance.head(25).to_string(index=False))\n",
    "\n",
    "# Save best parameters to file (optional)\n",
    "import json\n",
    "with open('best_lgb_params.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "print(\"\\n✅ Best parameters saved to 'best_lgb_params.json'\")\n",
    "\n",
    "# Optional: Plot optimization history\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot optimization history\n",
    "    optuna.visualization.matplotlib.plot_optimization_history(study, ax=axes[0])\n",
    "    axes[0].set_title('Optimization History')\n",
    "    \n",
    "    # Plot parameter importances\n",
    "    optuna.visualization.matplotlib.plot_param_importances(study, ax=axes[1])\n",
    "    axes[1].set_title('Parameter Importances')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('optuna_results.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"✅ Optimization plots saved to 'optuna_results.png'\")\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"\\n⚠️  Install matplotlib for visualization: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee831c7-9c25-45f7-976a-76f475f8f2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 25 Features:\n",
      "                   feature   importance\n",
      "        brand_price_median 97383.570609\n",
      "          brand_price_mean 72230.582977\n",
      "          normalized_value 28725.112673\n",
      "       price_per_norm_unit 23533.447547\n",
      "           brand_price_min  7346.459112\n",
      "               value_total  4002.426605\n",
      "           brand_price_max  3050.919962\n",
      "       pack_count_inferred  1270.831382\n",
      "        title_avg_word_len  1110.407192\n",
      "          title_char_count  1001.989447\n",
      " item_unit_size_from_title   940.833961\n",
      "     pack_count_from_title   743.565365\n",
      "        bullets_word_count   639.325641\n",
      "           bullets_avg_len   529.777716\n",
      "         title_digit_count   500.485639\n",
      "         title_punct_count   418.364085\n",
      "   title_unique_word_count   391.537754\n",
      "title_uppercase_word_count   362.827658\n",
      "        bullets_num_digits   345.826939\n",
      "          title_word_count   301.698374\n",
      "              bullet_count   164.361400\n",
      "           pack_count_text    60.898665\n",
      "\n",
      "Top 25 feature names: ['brand_price_median', 'brand_price_mean', 'normalized_value', 'price_per_norm_unit', 'brand_price_min', 'value_total', 'brand_price_max', 'pack_count_inferred', 'title_avg_word_len', 'title_char_count', 'item_unit_size_from_title', 'pack_count_from_title', 'bullets_word_count', 'bullets_avg_len', 'title_digit_count', 'title_punct_count', 'title_unique_word_count', 'title_uppercase_word_count', 'bullets_num_digits', 'title_word_count', 'bullet_count', 'pack_count_text']\n"
     ]
    }
   ],
   "source": [
    "# Get top 25 features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance(importance_type='gain')\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 25 Features:\")\n",
    "print(feature_importance.head(25).to_string(index=False))\n",
    "\n",
    "# Get list of top 25 feature names\n",
    "top_25_features = feature_importance.head(25)['feature'].tolist()\n",
    "print(f\"\\nTop 25 feature names: {top_25_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f585cfa-b160-4e90-a83e-4e13460db173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9963b4c-44c4-4f21-a262-e405b37cf5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536f839-5bff-4d03-9a59-769949bf3f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae503250-4050-4e16-867f-db3bc8b3b282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e81fb6-c828-4c02-89f4-fd9f99316652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46309124-c56f-410d-ba90-82f6202a65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "# import optuna\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculate Symmetric Mean Absolute Percentage Error.\"\"\"\n",
    "    return 100 * np.mean(\n",
    "        2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + 1e-8)\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_features(df, target_col=\"price\", exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Extract features and target from dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: Input dataframe\n",
    "        target_col: Name of target column\n",
    "        exclude_cols: Columns to exclude from features\n",
    "        \n",
    "    Returns:\n",
    "        X (DataFrame), y (Series), feature_cols (list)\n",
    "    \"\"\"\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = [\"sample_id\", \"price\", \"item_name_raw\"]\n",
    "    \n",
    "    # Select only numeric features\n",
    "    feature_cols = [\n",
    "        c for c in df.columns\n",
    "        if c not in exclude_cols and df[c].dtype != \"O\"\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "\n",
    "def transform_target(y, use_log=True):\n",
    "    \"\"\"Apply log transformation to target.\"\"\"\n",
    "    if use_log:\n",
    "        return np.log1p(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def inverse_transform_target(y, use_log=True):\n",
    "    \"\"\"Inverse transform predictions back to original scale.\"\"\"\n",
    "    if use_log:\n",
    "        return np.expm1(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def get_default_params():\n",
    "    \"\"\"Get default LightGBM parameters.\"\"\"\n",
    "    return {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mape\",\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 31,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 5,\n",
    "        \"min_child_samples\": 20,\n",
    "        \"reg_alpha\": 0.0,\n",
    "        \"reg_lambda\": 0.0,\n",
    "        \"seed\": 42,\n",
    "        \"verbose\": -1,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_val, \n",
    "    y_val, \n",
    "    params=None,\n",
    "    num_boost_round=2000,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=100,\n",
    "    use_log_target=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Train LightGBM model.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Training data\n",
    "        X_val, y_val: Validation data\n",
    "        params: LightGBM parameters (uses defaults if None)\n",
    "        num_boost_round: Maximum number of boosting rounds\n",
    "        early_stopping_rounds: Early stopping rounds\n",
    "        verbose_eval: Verbose evaluation frequency\n",
    "        use_log_target: Whether to use log-transformed target\n",
    "        \n",
    "    Returns:\n",
    "        trained model, training history\n",
    "    \"\"\"\n",
    "    # Transform targets if needed\n",
    "    y_train_transformed = transform_target(y_train, use_log_target)\n",
    "    y_val_transformed = transform_target(y_val, use_log_target)\n",
    "    \n",
    "    # Use default params if not provided\n",
    "    if params is None:\n",
    "        params = get_default_params()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_ds = lgb.Dataset(X_train, label=y_train_transformed)\n",
    "    val_ds = lgb.Dataset(X_val, label=y_val_transformed, reference=train_ds)\n",
    "    \n",
    "    # Train model\n",
    "    callbacks = []\n",
    "    if early_stopping_rounds:\n",
    "        callbacks.append(lgb.early_stopping(early_stopping_rounds))\n",
    "    if verbose_eval:\n",
    "        callbacks.append(lgb.log_evaluation(verbose_eval))\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_ds,\n",
    "        valid_sets=[train_ds, val_ds],\n",
    "        valid_names=[\"train\", \"val\"],\n",
    "        num_boost_round=num_boost_round,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, X, use_log_target=True):\n",
    "    \"\"\"Make predictions and inverse transform if needed.\"\"\"\n",
    "    y_pred = model.predict(X, num_iteration=model.best_iteration)\n",
    "    return inverse_transform_target(y_pred, use_log_target)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, use_log_target=True):\n",
    "    \"\"\"Evaluate model and return SMAPE score.\"\"\"\n",
    "    y_pred = predict(model, X_val, use_log_target)\n",
    "    score = smape(y_val.values, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e54d14fb-29df-4bfd-b413-47e6147a394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(\n",
    "    train_df_train,\n",
    "    train_df_val,\n",
    "    use_optuna=False,\n",
    "    n_trials=50,\n",
    "    custom_params=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete training pipeline.\n",
    "    \n",
    "    Args:\n",
    "        train_df_train: Training dataframe\n",
    "        train_df_val: Validation dataframe\n",
    "        use_optuna: Whether to use Optuna for hyperparameter tuning\n",
    "        n_trials: Number of Optuna trials (if use_optuna=True)\n",
    "        custom_params: Custom LightGBM parameters (if not using Optuna)\n",
    "        \n",
    "    Returns:\n",
    "        model, validation_score, best_params\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_train, y_train, feature_cols = prepare_features(train_df_train)\n",
    "    X_val, y_val, _ = prepare_features(train_df_val)\n",
    "    \n",
    "    print(f\"Training with {len(feature_cols)} features\")\n",
    "    print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}\")\n",
    "    \n",
    "    # Hyperparameter tuning\n",
    "    if use_optuna:\n",
    "        print(\"\\n=== Starting Optuna Hyperparameter Tuning ===\")\n",
    "        best_params, study = tune_hyperparameters(\n",
    "            X_train, y_train, X_val, y_val,\n",
    "            n_trials=n_trials,\n",
    "            use_log_target=True\n",
    "        )\n",
    "        # Add fixed params\n",
    "        best_params.update({\n",
    "            \"objective\": \"regression\",\n",
    "            \"metric\": \"mae\",\n",
    "            \"seed\": 42,\n",
    "            \"verbose\": -1\n",
    "        })\n",
    "    else:\n",
    "        best_params = custom_params if custom_params else get_default_params()\n",
    "    \n",
    "    # Train final model\n",
    "    print(\"\\n=== Training Final Model ===\")\n",
    "    model = train_model(\n",
    "        X_train, y_train, X_val, y_val,\n",
    "        params=best_params,\n",
    "        num_boost_round=2000,\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100,\n",
    "        use_log_target=True\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_score = evaluate_model(model, X_val, y_val, use_log_target=True)\n",
    "    print(f\"\\n=== Final Validation SMAPE: {val_score:.2f}% ===\")\n",
    "    \n",
    "    return model, val_score, best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44a6dc88-3c6a-41e2-8218-53563245954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: Default parameters\n",
      "Training with 27 features\n",
      "Train size: 15000, Val size: 15000\n",
      "\n",
      "=== Training Final Model ===\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's mape: 0.00401511\tval's mape: 0.00401511\n",
      "[200]\ttrain's mape: 0.00270892\tval's mape: 0.00270892\n",
      "[300]\ttrain's mape: 0.00244483\tval's mape: 0.00244483\n",
      "[400]\ttrain's mape: 0.00227862\tval's mape: 0.00227862\n",
      "[500]\ttrain's mape: 0.0021398\tval's mape: 0.0021398\n",
      "[600]\ttrain's mape: 0.00202009\tval's mape: 0.00202009\n",
      "[700]\ttrain's mape: 0.0019298\tval's mape: 0.0019298\n",
      "[800]\ttrain's mape: 0.00183392\tval's mape: 0.00183392\n",
      "[900]\ttrain's mape: 0.00176103\tval's mape: 0.00176103\n",
      "[1000]\ttrain's mape: 0.00168378\tval's mape: 0.00168378\n",
      "[1100]\ttrain's mape: 0.00162758\tval's mape: 0.00162758\n",
      "[1200]\ttrain's mape: 0.00156752\tval's mape: 0.00156752\n",
      "[1300]\ttrain's mape: 0.00151451\tval's mape: 0.00151451\n",
      "[1400]\ttrain's mape: 0.0014663\tval's mape: 0.0014663\n",
      "[1500]\ttrain's mape: 0.0014133\tval's mape: 0.0014133\n",
      "[1600]\ttrain's mape: 0.00138038\tval's mape: 0.00138038\n",
      "[1700]\ttrain's mape: 0.00133319\tval's mape: 0.00133319\n",
      "[1800]\ttrain's mape: 0.00128953\tval's mape: 0.00128953\n",
      "[1900]\ttrain's mape: 0.00125211\tval's mape: 0.00125211\n",
      "[2000]\ttrain's mape: 0.0012086\tval's mape: 0.0012086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttrain's mape: 0.0012086\tval's mape: 0.0012086\n",
      "\n",
      "=== Final Validation SMAPE: 0.33% ===\n"
     ]
    }
   ],
   "source": [
    "  # # Example 1: Train with default parameters\n",
    "print(\"Example 1: Default parameters\")\n",
    "model, score, params = run_pipeline(\n",
    "    train_df_train,\n",
    "    train_df_val,\n",
    "    use_optuna=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7e63e-c273-49f5-a437-2cc0a6e4d509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3386b-d1e5-4a57-9890-7c5699f4bf12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be799f-d28d-418a-9d39-c104035fc5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410615f-6cbb-445a-8095-ea55a4fc5a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e352a07d-b28b-4ae3-97d4-f05c76bcbea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'catalog_content', 'image_link', 'price', 'item_name_raw',\n",
       "       'bullets_list', 'value_total', 'unit_field_raw', 'brand_candidate_15',\n",
       "       'brand_candidate_2words', 'brand_candidate',\n",
       "       'item_unit_size_from_title', 'item_unit_type_from_title',\n",
       "       'pack_count_from_title', 'pack_count_inferred', 'pack_count_text',\n",
       "       'unit_normalized', 'normalized_value', 'normalized_unit',\n",
       "       'price_per_norm_unit', 'title_word_count', 'title_unique_word_count',\n",
       "       'title_avg_word_len', 'title_digit_count', 'title_punct_count',\n",
       "       'title_uppercase_word_count', 'title_char_count', 'bullet_count',\n",
       "       'bullets_combined', 'bullets_word_count', 'bullets_num_digits',\n",
       "       'bullets_avg_len', 'brand_price_mean', 'brand_price_median',\n",
       "       'brand_price_max', 'brand_price_min', 'price_vs_brand_mean',\n",
       "       'price_vs_brand_median', 'price_vs_brand_max', 'price_vs_brand_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e0c0ade-692b-477e-9477-f7e2110c7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(\n",
    "        2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true) + 1e-8)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01c7e63a-6699-4759-9ab0-bae7f713f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_train[\"log_price\"] = np.log1p(train_df_train[\"price\"])\n",
    "train_df_val[\"log_price\"] = np.log1p(train_df_val[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90acda92-96a1-447a-8b98-4f8ed2217bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    c for c in train_df_train.columns\n",
    "    if c not in [\"sample_id\", \"price\", \"item_name_raw\"]\n",
    "    and train_df_train[c].dtype != \"O\"  # exclude non-numeric\n",
    "]\n",
    "X_train, y_train = train_df_train[feature_cols], train_df[\"price\"]\n",
    "X_val, y_val = train_df_val[feature_cols], train_df_val[\"price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b73cb76f-ac98-492b-910f-25f59444bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cdcdf4b-f81f-4f6b-a55d-dedda0e26573",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'verbose_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m\n\u001b[1;32m      4\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val, label\u001b[38;5;241m=\u001b[39my_val, reference\u001b[38;5;241m=\u001b[39mtrain_ds)\n\u001b[1;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression_l1\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# robust loss\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 18\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# early_stopping_rounds=100,\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'verbose_eval'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_ds = lgb.Dataset(X_train, label=y_train)\n",
    "val_ds = lgb.Dataset(X_val, label=y_val, reference=train_ds)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"regression_l1\",  # robust loss\n",
    "    \"metric\": \"mae\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"seed\": 42,\n",
    "    \"verbose\": -1,\n",
    "}\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_ds,\n",
    "    valid_sets=[train_ds, val_ds],\n",
    "    valid_names=[\"train\", \"val\"],\n",
    "    num_boost_round=2000,\n",
    "    # early_stopping_rounds=100,\n",
    "    # verbose_eval=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cf90e-4199-4180-8a14-5c428f2f2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.expm1(model.predict(X_val, num_iteration=model.best_iteration))\n",
    "score = smape(y_val.values, y_pred)\n",
    "print(f\"Validation SMAPE: {score:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b342822-de64-45df-bbd3-4b7aaccd9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e8165b-ada1-4d20-a23a-84d61cc84199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec1136-6ba5-4a2a-9b3d-33c1c5856148",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, max_num_features=25, importance_type=\"gain\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo",
   "language": "python",
   "name": "neo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
